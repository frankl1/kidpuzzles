{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/a2c_digitspuzzle_nd1/A2C_1\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 9.69       |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 3          |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 138        |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.37      |\n",
      "|    explained_variance | 0.08666366 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | 0.195      |\n",
      "|    value_loss         | 0.0278     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 7.05       |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 3          |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 284        |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.27      |\n",
      "|    explained_variance | 0.14485693 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | 0.0343     |\n",
      "|    value_loss         | 0.00101    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 4.1       |\n",
      "|    ep_rew_mean        | 1         |\n",
      "| time/                 |           |\n",
      "|    fps                | 3         |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 443       |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.16     |\n",
      "|    explained_variance | 0.1311152 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -0.00695  |\n",
      "|    value_loss         | 0.000781  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.83       |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 3          |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 613        |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.881     |\n",
      "|    explained_variance | -1.9275055 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -0.023     |\n",
      "|    value_loss         | 0.000418   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.19       |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 3          |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 796        |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.798     |\n",
      "|    explained_variance | -1.3808568 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | -0.0285    |\n",
      "|    value_loss         | 0.00302    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.86       |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 3          |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 984        |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.62      |\n",
      "|    explained_variance | -1.6875815 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 0.000484   |\n",
      "|    value_loss         | 4.37e-05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.92       |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 2          |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 1179       |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.561     |\n",
      "|    explained_variance | -2.0977516 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -0.00938   |\n",
      "|    value_loss         | 0.000297   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.99       |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 2          |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 1373       |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.518     |\n",
      "|    explained_variance | 0.09374231 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | 0.0057     |\n",
      "|    value_loss         | 0.00241    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.71      |\n",
      "|    ep_rew_mean        | 1         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2         |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 1574      |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.435    |\n",
      "|    explained_variance | -57.12038 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -0.00193  |\n",
      "|    value_loss         | 0.00177   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.61       |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 2          |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 1774       |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.344     |\n",
      "|    explained_variance | 0.45809573 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | 0.00249    |\n",
      "|    value_loss         | 0.00011    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.6         |\n",
      "|    ep_rew_mean        | 1           |\n",
      "| time/                 |             |\n",
      "|    fps                | 2           |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 1978        |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -0.32       |\n",
      "|    explained_variance | -0.75813055 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.000741   |\n",
      "|    value_loss         | 8.79e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.5        |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 2          |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 2185       |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.28      |\n",
      "|    explained_variance | -37.911964 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 0.0269     |\n",
      "|    value_loss         | 0.00663    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.6        |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 2          |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 2392       |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.213     |\n",
      "|    explained_variance | 0.81426406 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 0.000477   |\n",
      "|    value_loss         | 8.48e-05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.43       |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 2          |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 2599       |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.219     |\n",
      "|    explained_variance | 0.29612005 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | -0.00136   |\n",
      "|    value_loss         | 0.000364   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.51       |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 2          |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 2806       |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.101     |\n",
      "|    explained_variance | 0.09675598 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -0.000204  |\n",
      "|    value_loss         | 0.000111   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.55       |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 2          |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 3011       |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.167     |\n",
      "|    explained_variance | 0.81730694 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 3.92e-05   |\n",
      "|    value_loss         | 6.83e-06   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.54      |\n",
      "|    ep_rew_mean        | 1         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2         |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 3219      |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.154    |\n",
      "|    explained_variance | -14.24974 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -0.000628 |\n",
      "|    value_loss         | 0.000486  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.47       |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 2          |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 3425       |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.22      |\n",
      "|    explained_variance | 0.89369947 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | -0.00114   |\n",
      "|    value_loss         | 1.83e-05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.57       |\n",
      "|    ep_rew_mean        | 1          |\n",
      "| time/                 |            |\n",
      "|    fps                | 2          |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 3632       |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.267     |\n",
      "|    explained_variance | -1.1884158 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 0.00326    |\n",
      "|    value_loss         | 0.000518   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.62      |\n",
      "|    ep_rew_mean        | 1         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2         |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 3836      |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.118    |\n",
      "|    explained_variance | 0.9937479 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -1.73e-06 |\n",
      "|    value_loss         | 2.78e-07  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x14941a8d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import FlattenObservation\n",
    "import kidspuzzles\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "n_digits = 1\n",
    "\n",
    "env = gym.make('kidspuzzles/DigitsPuzzleEnv-v0', render_mode = 'human', n_digits = n_digits)\n",
    "\n",
    "model = A2C(\"MultiInputPolicy\", env, verbose=1, device=\"mps\", tensorboard_log=f\"./logs/a2c_digitspuzzle_nd{n_digits}/\")\n",
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward:  [8.]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "vec_env = model.get_env()\n",
    "observations = vec_env.reset()\n",
    "reward_sum = 0\n",
    "for _ in range(10):\n",
    "    action, _state = model.predict(observations)\n",
    "    observations, reward, terminated, info = vec_env.step(action)\n",
    "    vec_env.render(\"human\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    reward_sum += reward\n",
    "    if terminated:\n",
    "        observations = vec_env.reset()\n",
    "\n",
    "print(\"Total reward: \", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
